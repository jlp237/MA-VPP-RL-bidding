{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e323e6-755a-4476-a70f-88b07c86dd07",
   "metadata": {},
   "source": [
    "# Tuning of all Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03607031-f4e8-46d0-928c-39b1a1cff8bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "from stable_baselines3 import TD3\n",
    "from stable_baselines3 import A2C\n",
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3 import DDPG\n",
    "from stable_baselines3 import PPO\n",
    "from sb3_contrib import TQC\n",
    "from sb3_contrib import TRPO\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from sb3_contrib import ARS\n",
    "\n",
    "from stable_baselines3.common.noise import NormalActionNoise,OrnsteinUhlenbeckActionNoise\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from gym.wrappers import RecordEpisodeStatistics\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from gym.envs.registration import register\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import subprocess\n",
    "from rl_zoo3 import linear_schedule\n",
    "\n",
    "import numpy as np\n",
    "import wandb\n",
    "\n",
    "from gym import make\n",
    "\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "\n",
    "from vpp_gym.vpp_gym.utils.register_env import register_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4176018c-9ba2-455b-8880-9040093b990e",
   "metadata": {},
   "source": [
    "## Seed Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f7f7a5-18f1-4df6-af87-431f180697ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ba063-764f-4d1d-a340-2ad6d1d85a89",
   "metadata": {},
   "source": [
    "## Register the Environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c07d26c-fe13-450b-8c14-3e9382f969f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG_NAME = \"vpp_config_1.json\"\n",
    "\n",
    "register_env(config=CONFIG_NAME, seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a018703-2b98-4312-a007-dabf896f8556",
   "metadata": {},
   "source": [
    "## Test the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e734a41-5452-4654-ac11-a2737749eff6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log_step: initial // slot: initial  log level = warning\n",
      "log_step: 0 slot: None logging_step: 0\n"
     ]
    }
   ],
   "source": [
    "# It will check your custom environment and output additional warnings if needed\n",
    "env_to_check = make('VPPBiddingEnv-TEST-v1', render_mode=None)\n",
    "check_env(env_to_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b272c9e-93ab-45a7-b31c-d4ba47539849",
   "metadata": {},
   "source": [
    "## Offline Training and later sync logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6c53c9a-c971-4545-887b-c6197dc93182",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_API_KEY\"] = \"0cea1eee5f42654eca0de365f0acca116367c9b4\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893eb40b-3616-49c7-b0e6-661297ace9f2",
   "metadata": {},
   "source": [
    "## Define Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54884c31-cd68-4643-bc7a-fb2032095518",
   "metadata": {},
   "source": [
    "### HER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76342922-378e-427a-8389-1be3c84aa5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_her_params(trial,hyperparams):\n",
    "    \"\"\"\n",
    "    Sampler for HerReplayBuffer hyperparams.\n",
    "    :param trial:\n",
    "    :parma hyperparams:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    her_kwargs = trial.her_kwargs.copy()\n",
    "    her_kwargs[\"n_sampled_goal\"] = trial.suggest_int(\"n_sampled_goal\", 1, 5)\n",
    "    her_kwargs[\"goal_selection_strategy\"] = trial.suggest_categorical(\n",
    "        \"goal_selection_strategy\", [\"final\", \"episode\", \"future\"]\n",
    "    )\n",
    "    her_kwargs[\"online_sampling\"] = trial.suggest_categorical(\"online_sampling\", [True, False])\n",
    "    hyperparams[\"replay_buffer_kwargs\"] = her_kwargs\n",
    "    return hyperparams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdd76255-8847-4cf7-bce4-b0cc7556088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_agent(trial):\n",
    "    \"\"\" Train the model and optimize\n",
    "        Optuna maximises the negative log likelihood, so we\n",
    "        need to negate the reward here\n",
    "    \"\"\"\n",
    "    \n",
    "    algo = study.user_attrs[\"algo\"]\n",
    "    nan_encountered = False\n",
    "    try: \n",
    "        model_params = HYPERPARAMS_SAMPLER[algo](trial)\n",
    "\n",
    "        config = dict(trial.params)\n",
    "        config[\"trial.number\"] = trial.number\n",
    "        wandb.init(\n",
    "            project=\"RL-optuna\",\n",
    "            entity=\"jlu237\", \n",
    "            sync_tensorboard=True,\n",
    "            config=config,\n",
    "            tags=[algo] + EXPERIMENT_TAGS,\n",
    "            reinit=True\n",
    "        )\n",
    "\n",
    "        env = make('VPPBiddingEnv-TUNING-v1')\n",
    "        env = Monitor(env) \n",
    "        env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "\n",
    "        if algo == \"R_PPO\": \n",
    "            model = ALGOS[algo]('MultiInputLstmPolicy', env, verbose=0, seed = 1, **model_params)\n",
    "        else:\n",
    "            model = ALGOS[algo]('MultiInputPolicy', env, verbose=0,  seed = 1, **model_params)\n",
    "            \n",
    "        print(model_params)\n",
    "    \n",
    "        # -------------- TRAINING -----------------\n",
    "        model.learn(total_timesteps=EXPERIMENT_TIMESTEPS,\n",
    "                    log_interval=1,\n",
    "                    progress_bar = True,\n",
    "                    callback=WandbCallback(\n",
    "                        gradient_save_freq=1,\n",
    "                        verbose=0))\n",
    "        \n",
    "        # -------------- EVALUATION -----------------\n",
    "        eval_env = make('VPPBiddingEnv-TUNING-EVAL-v1')\n",
    "        eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "        episodes = 140\n",
    "        for i_episode in range(episodes):\n",
    "            observation = eval_env.reset()\n",
    "            if algo == \"R_PPO\":\n",
    "                lstm_states = None\n",
    "                num_envs = 1\n",
    "                # Episode start signals are used to reset the lstm states\n",
    "                episode_starts = np.ones((num_envs,), dtype=bool)\n",
    "                for t in range(1):\n",
    "                    action, lstm_states = model.predict(observation, state=lstm_states, episode_start=episode_starts, deterministic=True)\n",
    "                    observation, reward, dones, info = eval_env.step(action)\n",
    "                    episode_starts = dones\n",
    "            else: \n",
    "                for t in range(1):\n",
    "                    action, _states = model.predict(observation, deterministic = True)\n",
    "                    observation, reward, done, info = eval_env.step(action)\n",
    "                        \n",
    "        total_reward_test = info[\"total_reward\"]\n",
    "        total_profit_test = info[\"total_profit\"]\n",
    "\n",
    "        print(\"Total Reward on Test Set: \" + str(total_reward_test))\n",
    "        print(\"Total Profit on Test Set: \" + str(total_profit_test))\n",
    "\n",
    "        wandb.log({\"total_reward_test\": total_reward_test, \n",
    "                   \"total_profit_test\": total_profit_test, \n",
    "                })\n",
    "        \n",
    "        wandb.finish()\n",
    "        eval_env.close()\n",
    "\n",
    "        return_code = subprocess.run(\"wandb sync wandb/latest-run\", shell=True)\n",
    "        \n",
    "    except (AssertionError, ValueError) as e:\n",
    "        # Sometimes, random hyperparams can generate NaN\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "        \n",
    "    finally:        \n",
    "        # Free memory\n",
    "        env.close()\n",
    "        \n",
    "    if nan_encountered: \n",
    "        return float(\"nan\")\n",
    "\n",
    "    return total_reward_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa370148-126b-499c-9ec4-ac20b7b4bda9",
   "metadata": {},
   "source": [
    "### A2C "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31eb215d-d102-4efc-a74a-3c727649b843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_a2c_params(trial: optuna.Trial):\n",
    "    \"\"\"\n",
    "    Sampler for a2c hyperparams.\n",
    "    :param trial:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    trial.using_her_replay_buffer = False\n",
    "    \n",
    "    n_steps_list = []\n",
    "    n_step = round(EXPERIMENT_TIMESTEPS/3)\n",
    "\n",
    "    while n_step > 1:\n",
    "        n_steps_list.append(n_step)\n",
    "        n_step = round(n_step/3)\n",
    "    \n",
    "    gamma = trial.suggest_categorical(\"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
    "    normalize_advantage = trial.suggest_categorical(\"normalize_advantage\", [False, True])\n",
    "    max_grad_norm = trial.suggest_categorical(\"max_grad_norm\", [0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5])\n",
    "    use_rms_prop = trial.suggest_categorical(\"use_rms_prop\", [False, True])\n",
    "    gae_lambda = trial.suggest_categorical(\"gae_lambda\", [0.7, 0.8, 0.9, 0.92, 0.95, 0.98, 0.99, 1.0])\n",
    "    #n_steps = trial.suggest_categorical(\"n_steps\", n_steps_list)\n",
    "    n_steps = trial.suggest_categorical(\"n_steps\", [2,3,4,5,6,7,8,9,10])\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "    ent_coef = trial.suggest_categorical('ent_coef', [0.1, 0.05, 0.025, 0.01, 0.001, 0.0001,  0.00000001])\n",
    "    vf_coef = trial.suggest_uniform(\"vf_coef\", 0.3, 1)\n",
    "    \n",
    "    # ------- policy_kwargs --------\n",
    "    lr_schedule = trial.suggest_categorical(\"lr_schedule\", [\"linear\", \"constant\"])\n",
    "    use_sde = trial.suggest_categorical(\"use_sde\", [False, True])\n",
    "    if use_sde is True:\n",
    "        sde_sample_freq = trial.suggest_categorical(\"sde_sample_freq\", [-1, 0, 1, 2, 3])\n",
    "        log_std_init = trial.suggest_uniform(\"log_std_init\", -4, 1)\n",
    "    sde_net_arch = trial.suggest_categorical(\"sde_net_arch\", [None, \"tiny\", \"small\"])\n",
    "    full_std = trial.suggest_categorical(\"full_std\", [False, True])\n",
    "    activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu', 'elu', 'leaky_relu'])\n",
    "    ortho_init = trial.suggest_categorical(\"ortho_init\", [False, True])\n",
    "\n",
    "    # NOTE: Add \"verybig\" to net_arch when tuning HER\n",
    "    net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\"])\n",
    "    # ------- policy_kwargs --------\n",
    "\n",
    "    \n",
    "    if lr_schedule == \"linear\":\n",
    "        learning_rate = linear_schedule(learning_rate)\n",
    "\n",
    "    net_arch = {\n",
    "        \"small\": [dict(pi=[64, 64], vf=[64, 64])],\n",
    "        \"medium\": [dict(pi=[256, 256], vf=[256, 256])],\n",
    "        \"big\": [dict(pi=[400, 400], vf=[400, 400])],\n",
    "    }[net_arch]\n",
    "    \n",
    "    sde_net_arch = {\n",
    "         None: None,\n",
    "         \"tiny\": [64],\n",
    "         \"small\": [64, 64],\n",
    "    }[sde_net_arch]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "    \n",
    "    hyperparams = {\n",
    "        \"n_steps\": n_steps,\n",
    "        \"gamma\": gamma,\n",
    "        \"gae_lambda\": gae_lambda,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"ent_coef\": ent_coef,\n",
    "        \"normalize_advantage\": normalize_advantage,\n",
    "        \"max_grad_norm\": max_grad_norm,\n",
    "        \"use_rms_prop\": use_rms_prop,\n",
    "        \"use_sde\": use_sde,\n",
    "        \"vf_coef\": vf_coef,\n",
    "        \"policy_kwargs\": dict(\n",
    "            net_arch=net_arch,\n",
    "            full_std=full_std,\n",
    "            activation_fn=activation_fn,\n",
    "            sde_net_arch=sde_net_arch,\n",
    "            ortho_init=ortho_init,\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    if trial.using_her_replay_buffer:\n",
    "        hyperparams = sample_her_params(trial, hyperparams)\n",
    "        \n",
    "    if use_sde is True:\n",
    "        hyperparams[\"sde_sample_freq\"] = sde_sample_freq\n",
    "        hyperparams[\"policy_kwargs\"][\"log_std_init\"] = log_std_init\n",
    " \n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a41d5-ecd4-4cef-827e-97d9f2dd071a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tuning TD3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6effaa8-4364-4935-b8df-65e559f918b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_td3_params(trial: optuna.Trial):\n",
    "    \"\"\"\n",
    "    Sampler for TD3 hyperparams.\n",
    "    :param trial:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    trial.using_her_replay_buffer = False\n",
    "\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 100, 128, 200])\n",
    "    buffer_size = trial.suggest_categorical(\"buffer_size\", [int(1e4), int(1e5), int(1e6)])\n",
    "    tau = trial.suggest_categorical(\"tau\", [0.001, 0.005, 0.01, 0.02, 0.05, 0.08])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
    "\n",
    "    train_freq = trial.suggest_categorical(\"train_freq\", [1, 2, 8, 32])\n",
    "    #gradient_steps = train_freq \n",
    "    gradient_steps = trial.suggest_categorical(\"gradient_steps\", [-1, 1, 2, 8, 32])\n",
    "    learning_starts = trial.suggest_categorical('learning_starts', [0, 1, 10, 20, 100, 200]) \n",
    "    noise_type = trial.suggest_categorical(\"noise_type\", [\"ornstein-uhlenbeck\", \"normal\", None])\n",
    "    noise_std = trial.suggest_uniform(\"noise_std\", 0, 1)\n",
    "    \n",
    "    policy_delay = trial.suggest_categorical(\"policy_delay\", [ 1, 2, 5])\n",
    "    target_policy_noise = trial.suggest_categorical(\"target_policy_noise\", [0.1, 0.2, 0.3])\n",
    "\n",
    "    if trial.using_her_replay_buffer: \n",
    "        net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\", \"verybig\"])\n",
    "    else:\n",
    "        net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\"])\n",
    "    activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu', 'elu', 'leaky_relu'])\n",
    "    \n",
    "    net_arch = {\n",
    "        \"small\": [64, 64],\n",
    "        \"medium\": [256, 256],\n",
    "        \"big\": [400, 300],\n",
    "        \"verybig\": [256, 256, 256],\n",
    "    }[net_arch]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "\n",
    "    hyperparams = {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"buffer_size\": buffer_size,\n",
    "        \"tau\": tau,\n",
    "        \"gamma\": gamma,\n",
    "        \"train_freq\": train_freq,\n",
    "        \"gradient_steps\": gradient_steps,\n",
    "        \"learning_starts\": learning_starts,\n",
    "        \"policy_delay\" : policy_delay,\n",
    "        \"target_policy_noise\": target_policy_noise,\n",
    "        \"policy_kwargs\": dict(\n",
    "            net_arch=net_arch, \n",
    "            activation_fn=activation_fn\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    n_actions = 12      \n",
    "    if noise_type == \"normal\":\n",
    "        hyperparams[\"action_noise\"] = NormalActionNoise(\n",
    "            mean=np.zeros(n_actions), sigma=noise_std * np.ones(n_actions)\n",
    "        )\n",
    "    elif noise_type == \"ornstein-uhlenbeck\":\n",
    "        hyperparams[\"action_noise\"] = OrnsteinUhlenbeckActionNoise(\n",
    "            mean=np.zeros(n_actions), sigma=noise_std * np.ones(n_actions)\n",
    "        )\n",
    "\n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07d4b7e-e6a7-4e9d-ab5c-c79f3545f429",
   "metadata": {},
   "source": [
    "### Tuning SAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e33b71c4-de8b-4cf4-8d79-fe1ca8dd41c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_sac_params(trial: optuna.Trial):\n",
    "    \"\"\"\n",
    "    Sampler for SAC hyperparams.\n",
    "    :param trial:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    trial.using_her_replay_buffer = False\n",
    "\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 100, 128, 200])\n",
    "    buffer_size = trial.suggest_categorical(\"buffer_size\", [int(1e4), int(1e5), int(1e6)])\n",
    "    tau = trial.suggest_categorical(\"tau\", [0.001, 0.005, 0.01, 0.02, 0.05, 0.08])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
    "    train_freq = trial.suggest_categorical(\"train_freq\", [1, 2, 3, 4, 8, 16, 32])\n",
    "    # gradient_steps takes too much time\n",
    "    gradient_steps = trial.suggest_categorical(\"gradient_steps\", [-1, 1, 2, 8, 32])\n",
    "    learning_starts = trial.suggest_categorical('learning_starts', [0, 1, 10, 20, 100, 200]) \n",
    "\n",
    "    noise_type = trial.suggest_categorical(\"noise_type\", [\"ornstein-uhlenbeck\", \"normal\", None])\n",
    "    noise_std = trial.suggest_uniform(\"noise_std\", 0, 1)\n",
    "    policy_delay = trial.suggest_categorical(\"policy_delay\", [ 1, 2, 5])\n",
    "    target_policy_noise = trial.suggest_categorical(\"target_policy_noise\", [0.1, 0.2, 0.3])\n",
    "       \n",
    "    ent_coef = trial.suggest_categorical('ent_coef', ['auto',  'auto_0.1', 0.5, 0.1, 0.05, 0.01, 0.0001])\n",
    "\n",
    "    if ent_coef == 'auto' or 'auto_0.1':\n",
    "        target_entropy = trial.suggest_categorical('target_entropy', ['auto', 10 , 5, 1, 0, -1, -5, -10])\n",
    "\n",
    "    if trial.using_her_replay_buffer: \n",
    "        net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\", \"verybig\"])\n",
    "    else:\n",
    "        net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\"])\n",
    "    \n",
    "    \n",
    "    net_arch = {\n",
    "        \"small\": [64, 64],\n",
    "        \"medium\": [256, 256],\n",
    "        \"big\": [400, 300],\n",
    "        \"verybig\": [256, 256, 256],\n",
    "    }[net_arch]\n",
    "\n",
    "\n",
    "    # ------- policy_kwargs --------\n",
    "    use_sde = trial.suggest_categorical(\"use_sde\", [False, True])\n",
    "    if use_sde is True:\n",
    "        sde_sample_freq = trial.suggest_categorical(\"sde_sample_freq\", [-1, 0, 1, 2, 3])\n",
    "        log_std_init = trial.suggest_uniform(\"log_std_init\", -4, 1)\n",
    "    \n",
    "    #activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu', 'elu', 'leaky_relu'])\n",
    "    activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu'])\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "    # --------------------\n",
    " \n",
    "    hyperparams = {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"buffer_size\": buffer_size,\n",
    "        \"learning_starts\": learning_starts,\n",
    "        \"train_freq\": train_freq,\n",
    "        \"gradient_steps\": gradient_steps,\n",
    "        \"ent_coef\": ent_coef,\n",
    "        \"tau\": tau,\n",
    "        \"gamma\": gamma,\n",
    "        \"policy_kwargs\": dict(net_arch=net_arch, \n",
    "                              activation_fn=activation_fn\n",
    "                             ),\n",
    "    }\n",
    "    \n",
    "    if trial.using_her_replay_buffer:\n",
    "        hyperparams = sample_her_params(trial, hyperparams)\n",
    "        \n",
    "    if use_sde is True:\n",
    "        hyperparams[\"sde_sample_freq\"] = sde_sample_freq\n",
    "        hyperparams[\"policy_kwargs\"][\"log_std_init\"] = log_std_init\n",
    "\n",
    "        \n",
    "    if ent_coef == 'auto' or 'â€˜auto_0.1':\n",
    "        hyperparams[\"target_entropy\"] = target_entropy\n",
    "\n",
    "    n_actions = 12      \n",
    "    if noise_type == \"normal\":\n",
    "        hyperparams[\"action_noise\"] = NormalActionNoise(\n",
    "            mean=np.zeros(n_actions), sigma=noise_std * np.ones(n_actions)\n",
    "        )\n",
    "    elif noise_type == \"ornstein-uhlenbeck\":\n",
    "        \n",
    "        hyperparams[\"action_noise\"] = OrnsteinUhlenbeckActionNoise(\n",
    "            mean=np.zeros(n_actions), sigma=noise_std * np.ones(n_actions)\n",
    "        )\n",
    "\n",
    "    return hyperparams\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584a673c-6b9a-4eda-9fe4-43afefcdd0f3",
   "metadata": {},
   "source": [
    "### Tuning DDPG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "29bd0699-c01c-42a2-b39b-147a8a0d7036",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_ddpg_params(trial: optuna.Trial):\n",
    "    \"\"\"\n",
    "    Sampler for DDPG hyperparams.\n",
    "    :param trial:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    trial.using_her_replay_buffer = False\n",
    "\n",
    "    \n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "    buffer_size = trial.suggest_categorical(\"buffer_size\", [int(1e4), int(1e5), int(1e6)])\n",
    "    learning_starts = trial.suggest_categorical('learning_starts', [0, 1, 10, 20, 100, 200]) \n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 100, 128, 200])\n",
    "    tau = trial.suggest_categorical(\"tau\", [0.001, 0.005, 0.01, 0.02, 0.05, 0.08])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
    "    train_freq = trial.suggest_categorical(\"train_freq\", [1, 2, 8, 32])\n",
    "    # gradient_steps takes too much time\n",
    "    gradient_steps = trial.suggest_categorical(\"gradient_steps\", [-1, 1, 2, 8, 32])\n",
    "    noise_type = trial.suggest_categorical(\"noise_type\", [\"ornstein-uhlenbeck\", \"normal\", None])\n",
    "    noise_std = trial.suggest_uniform(\"noise_std\", 0, 1)\n",
    "    \n",
    "    if trial.using_her_replay_buffer: \n",
    "        net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\", \"verybig\"])\n",
    "    else:\n",
    "        net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\"])\n",
    "        \n",
    "    net_arch = {\n",
    "        \"small\": [64, 64],\n",
    "        \"medium\": [256, 256],\n",
    "        \"big\": [400, 300],\n",
    "        \"verybig\": [256, 256, 256],\n",
    "    }[net_arch]\n",
    "    \n",
    "    # ------- policy_kwargs --------\n",
    "    #activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu', 'elu', 'leaky_relu'])\n",
    "    activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu'])\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "    # --------------------\n",
    "\n",
    "    hyperparams = {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"buffer_size\": buffer_size,\n",
    "        \"learning_starts\": learning_starts,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"tau\": tau,\n",
    "        \"gamma\": gamma,\n",
    "        \"train_freq\": train_freq,\n",
    "        \"gradient_steps\": gradient_steps,\n",
    "        \"policy_kwargs\": dict(net_arch=net_arch, \n",
    "                              activation_fn=activation_fn\n",
    "                             ),\n",
    "    }\n",
    "\n",
    "    n_actions = 12      \n",
    "    if noise_type == \"normal\":\n",
    "        hyperparams[\"action_noise\"] = NormalActionNoise(\n",
    "            mean=np.zeros(n_actions), sigma=noise_std * np.ones(n_actions)\n",
    "        )\n",
    "    elif noise_type == \"ornstein-uhlenbeck\":\n",
    "        \n",
    "        hyperparams[\"action_noise\"] = OrnsteinUhlenbeckActionNoise(\n",
    "            mean=np.zeros(n_actions), sigma=noise_std * np.ones(n_actions)\n",
    "        )\n",
    "\n",
    "    if trial.using_her_replay_buffer:\n",
    "        hyperparams = sample_her_params(trial, hyperparams)\n",
    "\n",
    "    return hyperparams\n",
    "\n",
    "\n",
    "def optimize_agent_ddpg(trial):\n",
    "    \"\"\" Train the model and optimize\n",
    "        Optuna maximises the negative log likelihood, so we\n",
    "        need to negate the reward here\n",
    "    \"\"\"\n",
    "    \n",
    "    nan_encountered = False\n",
    "    try: \n",
    "        model_params = sample_ddpg_params(trial)\n",
    "\n",
    "        # init tracking experiment.\n",
    "        # hyper-parameters, trial id are stored.\n",
    "        config = dict(trial.params)\n",
    "        config[\"trial.number\"] = trial.number\n",
    "        wandb.init(\n",
    "            project=\"RL-optuna\",\n",
    "            entity=\"jlu237\", \n",
    "            sync_tensorboard=True,\n",
    "            config=config,\n",
    "            tags=[\"DDPG\"] + EXPERIMENT_TAGS,\n",
    "            reinit=True\n",
    "        )\n",
    "\n",
    "        env = make('VPPBiddingEnv-TUNING-v1')\n",
    "        env = Monitor(env) \n",
    "        env = RecordEpisodeStatistics(env) # record stats such as returns\n",
    "        model = DDPG('MultiInputPolicy', env, verbose=0,  seed = 1, **model_params)\n",
    "        print(model_params)\n",
    "    \n",
    "        # -------------- TRAINING -----------------\n",
    "        model.learn(total_timesteps=EXPERIMENT_TIMESTEPS,\n",
    "                    log_interval=1,\n",
    "                    progress_bar = True,\n",
    "                    callback=WandbCallback(\n",
    "                        gradient_save_freq=1,\n",
    "                        verbose=0))\n",
    "        \n",
    "        # -------------- EVALUATION -----------------\n",
    "        eval_env = make('VPPBiddingEnv-TUNING-EVAL-v1')\n",
    "        eval_env = RecordEpisodeStatistics(eval_env) # record stats such as returns\n",
    "        episodes = 140\n",
    "        for i_episode in range(episodes):\n",
    "            observation = eval_env.reset()\n",
    "            for t in range(1):\n",
    "                eval_env.render()\n",
    "                #logging.debug(\"observation : \" + str(observation), extra={'log_step': str(i_episode), 'slot': 'test'})\n",
    "                action, _states = model.predict(observation, deterministic = True)\n",
    "                observation, reward, done, info = eval_env.step(action)\n",
    "                if done:\n",
    "                    break\n",
    "        total_reward_test = info[\"total_reward\"]\n",
    "        total_profit_test = info[\"total_profit\"]\n",
    "\n",
    "        mean_episode_reward_test = info[\"total_reward\"] / episodes\n",
    "        mean_episode_profit_test = info[\"total_profit\"] / episodes\n",
    "\n",
    "        print(\"Total Reward on Test Set: \" + str(total_reward_test))\n",
    "        print(\"Total Profit on Test Set: \" + str(total_profit_test))\n",
    "        print(\"Mean Episode Reward: \" + str(mean_episode_reward_test))\n",
    "        print(\"Mean Episode Profit: \" + str(mean_episode_profit_test))\n",
    "\n",
    "        wandb.log({\"total_reward_test\": total_reward_test, \n",
    "                   \"total_profit_test\": total_profit_test, \n",
    "                   \"mean_episode_reward_test\": mean_episode_reward_test,\n",
    "                   \"mean_episode_profit_test\": mean_episode_profit_test,\n",
    "                })\n",
    "        wandb.finish()\n",
    "        eval_env.close()\n",
    "\n",
    "        return_code = subprocess.run(\"wandb sync wandb/latest-run\", shell=True)\n",
    "        \n",
    "    except AssertionError as e:\n",
    "        # Sometimes, random hyperparams can generate NaN\n",
    "        print(e)\n",
    "        nan_encountered = True\n",
    "        \n",
    "    finally:        \n",
    "        # Free memory\n",
    "        env.close()\n",
    "        \n",
    "    if nan_encountered: \n",
    "        return float(\"nan\")\n",
    "\n",
    "    return total_reward_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630ccc60-f8ce-4590-857c-c994997f3584",
   "metadata": {},
   "source": [
    "### Tuning RecurrentPPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45cc5aac-bd2a-453b-b52c-0e994a3aebf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_rppo_params(trial: optuna.Trial):\n",
    "    \"\"\"\n",
    "    Sampler for RecurrentPPO hyperparams.\n",
    "    :param trial:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    trial.using_her_replay_buffer = False\n",
    "    \n",
    "    n_steps_list = []\n",
    "    n_step = round(EXPERIMENT_TIMESTEPS/3)\n",
    "\n",
    "    while n_step > 1:\n",
    "        n_steps_list.append(n_step)\n",
    "        n_step = round(n_step/3)\n",
    "        \n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "    #n_steps = trial.suggest_categorical(\"n_steps\", n_steps_list)\n",
    "    n_steps = trial.suggest_categorical(\"n_steps\", [2,3,4,5,6,7,8,9,10])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 100, 128, 200])\n",
    "    n_epochs = trial.suggest_categorical(\"n_epochs\", [1, 5, 10, 20])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
    "    gae_lambda = trial.suggest_categorical(\"gae_lambda\", [0.7, 0.8, 0.9, 0.92, 0.95, 0.98, 0.99, 1.0])\n",
    "    clip_range = trial.suggest_categorical(\"clip_range\", [0.1, 0.2, 0.3, 0.4])\n",
    "    normalize_advantage = trial.suggest_categorical(\"normalize_advantage\", [False, True])\n",
    "    ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
    "    vf_coef = trial.suggest_uniform(\"vf_coef\", 0, 1)\n",
    "    max_grad_norm = trial.suggest_categorical(\"max_grad_norm\", [0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 5])\n",
    "    target_kl = trial.suggest_categorical(\"target_kl\", [0.1, 0.05, 0.03, 0.02, 0.01, 0.005, 0.001])\n",
    "    \n",
    "    # ------- policy_kwargs --------\n",
    "    lr_schedule = trial.suggest_categorical(\"lr_schedule\", [\"linear\", \"constant\"])\n",
    "    use_sde = trial.suggest_categorical(\"use_sde\", [False, True])\n",
    "    if use_sde is True:\n",
    "        sde_sample_freq = trial.suggest_categorical(\"sde_sample_freq\", [-1, 0, 1, 2, 3])\n",
    "        log_std_init = trial.suggest_uniform(\"log_std_init\", -4, 1)\n",
    "    full_std = trial.suggest_categorical(\"full_std\", [False, True])\n",
    "    activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu', 'elu', 'leaky_relu'])\n",
    "    ortho_init = trial.suggest_categorical(\"ortho_init\", [False, True])\n",
    "\n",
    "    # NOTE: Add \"verybig\" to net_arch when tuning HER\n",
    "    net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\"])\n",
    "    # ------- policy_kwargs --------\n",
    "    \n",
    "    if batch_size > n_steps:\n",
    "        batch_size = n_steps\n",
    "\n",
    "    if lr_schedule == \"linear\":\n",
    "        learning_rate = linear_schedule(learning_rate)\n",
    "\n",
    "    net_arch = {\n",
    "        \"small\": [dict(pi=[64, 64], vf=[64, 64])],\n",
    "        \"medium\": [dict(pi=[256, 256], vf=[256, 256])],\n",
    "        \"big\": [dict(pi=[400, 400], vf=[400, 400])],\n",
    "    }[net_arch]\n",
    "    \n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "    \n",
    "    hyperparams = {\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"n_steps\": n_steps,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"n_epochs\": n_epochs,\n",
    "        \"gamma\": gamma,\n",
    "        \"gae_lambda\": gae_lambda,\n",
    "        \"clip_range\": clip_range,\n",
    "        \"normalize_advantage\": normalize_advantage,\n",
    "        \"ent_coef\": ent_coef,\n",
    "        \"vf_coef\": vf_coef,\n",
    "        \"max_grad_norm\": max_grad_norm,\n",
    "        \"target_kl\": target_kl,\n",
    "        \"policy_kwargs\": dict(\n",
    "            net_arch=net_arch,\n",
    "            full_std=full_std,\n",
    "            activation_fn=activation_fn,\n",
    "            ortho_init=ortho_init,\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "     \n",
    "    if trial.using_her_replay_buffer:\n",
    "        hyperparams = sample_her_params(trial, hyperparams)\n",
    "        \n",
    "    if use_sde is True:\n",
    "        hyperparams[\"sde_sample_freq\"] = sde_sample_freq\n",
    "        hyperparams[\"policy_kwargs\"][\"log_std_init\"] = log_std_init\n",
    "\n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545ae0ad-0b1f-43e3-b690-9e31348d4558",
   "metadata": {},
   "source": [
    "### Tuning TRPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1f24dc-25b2-44de-afe5-9c3a6ae9a910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sample_trpo_params(trial):\n",
    "    \"\"\"\n",
    "    Sampler for TRPO hyperparams.\n",
    "    :param trial:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    trial.using_her_replay_buffer = False\n",
    "    \n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "    n_steps = trial.suggest_categorical(\"n_steps\", [2,3,4,5,6,7,8,9,10])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 100, 128, 200])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
    "    cg_max_steps = trial.suggest_categorical(\"cg_max_steps\", [5, 10, 15, 20, 25, 30])\n",
    "    cg_damping = trial.suggest_categorical(\"cg_damping\", [0.5, 0.2, 0.1, 0.05, 0.01])\n",
    "    line_search_shrinking_factor = trial.suggest_categorical(\"line_search_shrinking_factor\", [0.6, 0.7, 0.8, 0.9])\n",
    "    line_search_max_iter = trial.suggest_categorical(\"line_search_max_iter\", [1, 5, 10, 15, 20])\n",
    "    n_critic_updates = trial.suggest_categorical(\"n_critic_updates\", [1, 5, 10, 20, 25])\n",
    "    gae_lambda = trial.suggest_categorical(\"gae_lambda\", [0.8, 0.9, 0.92, 0.95, 0.98, 0.99, 1.0])\n",
    "    normalize_advantage = trial.suggest_categorical(\"normalize_advantage\", [False, True])\n",
    "    use_sde = trial.suggest_categorical(\"use_sde\", [False, True])\n",
    "    if use_sde is True:\n",
    "        sde_sample_freq = trial.suggest_categorical(\"sde_sample_freq\", [-1, 0, 1, 2, 3])    \n",
    "    target_kl = trial.suggest_categorical(\"target_kl\", [0.1, 0.05, 0.03, 0.02, 0.01, 0.005, 0.001])\n",
    "    \n",
    "    # ------- policy_kwargs --------\n",
    "    if use_sde is True:\n",
    "        log_std_init = trial.suggest_uniform(\"log_std_init\", -4, 1)\n",
    "        full_std = trial.suggest_categorical('full_std', [False, True])\n",
    "    sde_net_arch = trial.suggest_categorical(\"sde_net_arch\", [None, \"tiny\", \"small\"])\n",
    "    lr_schedule = trial.suggest_categorical(\"lr_schedule\", [\"linear\", \"constant\"])\n",
    "    net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\"])\n",
    "    ortho_init = trial.suggest_categorical('ortho_init', [False, True])\n",
    "    activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu', 'elu', 'leaky_relu'])\n",
    "\n",
    "    if batch_size > n_steps:\n",
    "        batch_size = n_steps\n",
    "\n",
    "    if lr_schedule == \"linear\":\n",
    "        learning_rate = linear_schedule(learning_rate)\n",
    "\n",
    "    net_arch = {\n",
    "        \"small\": [dict(pi=[64, 64], vf=[64, 64])],\n",
    "        \"medium\": [dict(pi=[256, 256], vf=[256, 256])],\n",
    "        \"big\": [dict(pi=[400, 400], vf=[400, 400])],\n",
    "    }[net_arch]\n",
    "    \n",
    "    sde_net_arch = {\n",
    "         None: None,\n",
    "         \"tiny\": [64],\n",
    "         \"small\": [64, 64],\n",
    "    }[sde_net_arch]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "\n",
    "    hyperparams = {\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"n_steps\": n_steps,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"gamma\": gamma,\n",
    "            \"cg_max_steps\": cg_max_steps,\n",
    "            \"cg_damping\": cg_damping,\n",
    "            \"line_search_shrinking_factor\": line_search_shrinking_factor,\n",
    "            \"line_search_max_iter\": line_search_max_iter,\n",
    "            \"n_critic_updates\": n_critic_updates,\n",
    "            \"gae_lambda\": gae_lambda,\n",
    "            \"normalize_advantage\": normalize_advantage,\n",
    "            \"use_sde\": use_sde,\n",
    "            \"target_kl\": target_kl,\n",
    "            \"policy_kwargs\": dict(\n",
    "                net_arch=net_arch,\n",
    "                ortho_init=ortho_init,\n",
    "                activation_fn=activation_fn,\n",
    "            ),\n",
    "        }\n",
    "    \n",
    "     \n",
    "    if trial.using_her_replay_buffer:\n",
    "        hyperparams = sample_her_params(trial, hyperparams)\n",
    "        \n",
    "    if use_sde is True:\n",
    "        hyperparams[\"sde_sample_freq\"] = sde_sample_freq\n",
    "        hyperparams[\"policy_kwargs\"][\"log_std_init\"] = log_std_init\n",
    "        hyperparams[\"policy_kwargs\"][\"full_std\"] = full_std\n",
    "        hyperparams[\"policy_kwargs\"][\"sde_net_arch\"] = sde_net_arch       \n",
    "        \n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16756f87-57f3-4b4d-9c68-bb2c39f7ff12",
   "metadata": {},
   "source": [
    "### Tuning PPO "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34c060a4-89a7-460e-83bb-f6aa32a830a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_ppo_params(trial: optuna.Trial):\n",
    "    \"\"\"\n",
    "    Sampler for PPO hyperparams.\n",
    "    :param trial:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    trial.using_her_replay_buffer = False\n",
    "    \n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 1e-5, 1)\n",
    "    n_steps = trial.suggest_categorical(\"n_steps\", [2,3,4,5,6,7,8,9,10])\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [8, 16, 32, 64, 100, 128, 200])\n",
    "    n_epochs = trial.suggest_categorical(\"n_epochs\", [1, 5, 10, 20])\n",
    "    gamma = trial.suggest_categorical(\"gamma\", [0.9, 0.95, 0.98, 0.99, 0.995, 0.999, 0.9999])\n",
    "    gae_lambda = trial.suggest_categorical(\"gae_lambda\", [0.7, 0.8, 0.9, 0.92, 0.95, 0.98, 0.99, 1.0])\n",
    "    clip_range = trial.suggest_categorical(\"clip_range\", [0.1, 0.2, 0.3, 0.4])\n",
    "    normalize_advantage = trial.suggest_categorical(\"normalize_advantage\", [False, True])\n",
    "    ent_coef = trial.suggest_loguniform(\"ent_coef\", 0.00000001, 0.1)\n",
    "    vf_coef = trial.suggest_uniform(\"vf_coef\", 0, 1)\n",
    "    max_grad_norm = trial.suggest_categorical(\"max_grad_norm\", [0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 1, 2, 3, 4, 5])\n",
    "    use_sde = trial.suggest_categorical(\"use_sde\", [False, True])\n",
    "    if use_sde is True:\n",
    "        sde_sample_freq = trial.suggest_categorical(\"sde_sample_freq\", [-1, 0, 1, 2, 3])    \n",
    "    target_kl = trial.suggest_categorical(\"target_kl\", [0.1, 0.05, 0.03, 0.02, 0.01, 0.005, 0.001])\n",
    "    \n",
    "    \n",
    "    # ------- policy_kwargs --------\n",
    "    lr_schedule = trial.suggest_categorical('lr_schedule', ['linear', 'constant'])\n",
    "    net_arch = trial.suggest_categorical(\"net_arch\", [\"small\", \"medium\", \"big\"])\n",
    "    activation_fn = trial.suggest_categorical('activation_fn', ['tanh', 'relu', 'elu', 'leaky_relu'])\n",
    "    ortho_init = trial.suggest_categorical('ortho_init', [False, True])\n",
    "    if use_sde is True:\n",
    "        log_std_init = trial.suggest_uniform(\"log_std_init\", -4, 1)\n",
    "        full_std = trial.suggest_categorical('full_std', [False, True])\n",
    "\n",
    "    if batch_size > n_steps:\n",
    "        batch_size = n_steps\n",
    "\n",
    "    if lr_schedule == \"linear\":\n",
    "        learning_rate = linear_schedule(learning_rate)\n",
    "\n",
    "    net_arch = {\n",
    "        \"small\": [dict(pi=[64, 64], vf=[64, 64])],\n",
    "        \"medium\": [dict(pi=[256, 256], vf=[256, 256])],\n",
    "        \"big\": [dict(pi=[400, 400], vf=[400, 400])],\n",
    "    }[net_arch]\n",
    "\n",
    "    activation_fn = {\"tanh\": nn.Tanh, \"relu\": nn.ReLU, \"elu\": nn.ELU, \"leaky_relu\": nn.LeakyReLU}[activation_fn]\n",
    "\n",
    "    hyperparams = {\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"n_steps\": n_steps,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"n_epochs\": n_epochs,\n",
    "            \"gamma\": gamma,\n",
    "            \"gae_lambda\": gae_lambda,\n",
    "            \"clip_range\": clip_range,\n",
    "            \"normalize_advantage\": normalize_advantage,\n",
    "            \"ent_coef\": ent_coef,\n",
    "            \"vf_coef\": vf_coef,\n",
    "            \"max_grad_norm\": max_grad_norm,\n",
    "            \"use_sde\": use_sde,\n",
    "            \"target_kl\": target_kl,\n",
    "            \"policy_kwargs\": dict(\n",
    "                    net_arch=net_arch,\n",
    "                    ortho_init=ortho_init,\n",
    "                    activation_fn=activation_fn,\n",
    "            ),\n",
    "        }\n",
    "    \n",
    "  \n",
    "    if trial.using_her_replay_buffer:\n",
    "        hyperparams = sample_her_params(trial, hyperparams)\n",
    "        \n",
    "    if use_sde is True:\n",
    "        hyperparams[\"sde_sample_freq\"] = sde_sample_freq\n",
    "        hyperparams[\"policy_kwargs\"][\"log_std_init\"] = log_std_init\n",
    "        hyperparams[\"policy_kwargs\"][\"full_std\"] = full_std\n",
    "        \n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3f6b2-d483-4e90-bd69-fdaf3c3ce643",
   "metadata": {},
   "source": [
    "### Tuning TQC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30f448ef-015b-477c-852a-f50ad3ca11fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_tqc_params(trial: optuna.Trial):\n",
    "    \"\"\"\n",
    "    Sampler for TQC hyperparams.\n",
    "    :param trial:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # TQC is SAC + Distributional RL\n",
    "    hyperparams = sample_sac_params(trial)\n",
    "\n",
    "    n_quantiles = trial.suggest_int(\"n_quantiles\", 5, 50)\n",
    "    top_quantiles_to_drop_per_net = trial.suggest_int(\"top_quantiles_to_drop_per_net\", 0, n_quantiles - 1)\n",
    "\n",
    "    hyperparams[\"policy_kwargs\"].update({\"n_quantiles\": n_quantiles})\n",
    "    hyperparams[\"top_quantiles_to_drop_per_net\"] = top_quantiles_to_drop_per_net\n",
    "\n",
    "    return hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4a045-ed17-4134-9da8-ad8a5c2eaa89",
   "metadata": {},
   "source": [
    "# Run the Studies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "738b890a-756a-4785-a609-08f2159ff854",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPERPARAMS_SAMPLER = {\n",
    "    \"A2C\": sample_a2c_params,\n",
    "    \"DDPG\": sample_ddpg_params,\n",
    "    \"SAC\": sample_sac_params,\n",
    "    \"PPO\": sample_ppo_params,\n",
    "    \"TD3\": sample_td3_params,\n",
    "    #\"DQN\": sample_dqn_params,\n",
    "    # SB3 Contrib,\n",
    "    \"TQC\": sample_tqc_params,\n",
    "    \"TRPO\": sample_trpo_params,\n",
    "    \"R_PPO\": sample_rppo_params,\n",
    "}\n",
    "\n",
    "ALGOS = {\n",
    "    \"A2C\": A2C,\n",
    "    \"DDPG\": DDPG,\n",
    "    \"PPO\": PPO,\n",
    "    \"SAC\": SAC,\n",
    "    \"TD3\": TD3,\n",
    "    #\"DQN\": DQN,\n",
    "    # SB3 Contrib,\n",
    "    \"TQC\": TQC,\n",
    "    \"TRPO\": TRPO,\n",
    "    \"R_PPO\": RecurrentPPO,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b23f3f9-9996-4a87-8925-f8f496cf16c9",
   "metadata": {},
   "source": [
    "## Globals "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67303de9-3fd4-482a-9218-47b5df3876ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_TAGS = [\"tuning_4\"] # tuning_4 = after data refinement (no noise, new activaiton distribution)\n",
    "EXPERIMENT_TIMESTEPS = 2785   #5570     # 2785 #how many episodes to train\n",
    "N_TRIALS = 1                  # 20 #how many experiments to run\n",
    "N_STARTUP_TRIALS = 1          # 20 #how long to use random sampling before using TPESampler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3105c2cb-913c-4de4-836d-158ab5259b7c",
   "metadata": {},
   "source": [
    "## Define Parameter Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c44c8a0-79e6-445b-9c12-4f0266186940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set pytorch num threads to 1 for faster training\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "sampler = TPESampler(n_startup_trials=N_STARTUP_TRIALS)\n",
    "\n",
    "# Do not prune before 1/3 of the max budget is used\n",
    "pruner = MedianPruner(n_startup_trials=N_STARTUP_TRIALS, n_warmup_steps=EXPERIMENT_TIMESTEPS // 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5205c172-c134-4840-b940-f0ffbd104a87",
   "metadata": {},
   "source": [
    "## All Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e487b165-2ad1-405e-9573-e84478bc2d45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 13:07:03,273]\u001b[0m A new study created in memory with name: no-name-903b81c9-9570-49bd-8cb0-a2547bb77ea9\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning : SAC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7586e4dd69434a18bc326e3dec98d0aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 7.890447483613503e-05, 'batch_size': 100, 'buffer_size': 10000, 'learning_starts': 200, 'train_freq': 2, 'gradient_steps': 8, 'ent_coef': 0.5, 'tau': 0.005, 'gamma': 0.99, 'policy_kwargs': {'net_arch': [256, 256], 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'use_sde': False}, 'target_entropy': -10, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.82730392 0.82730392 0.82730392 0.82730392 0.82730392 0.82730392\n",
      " 0.82730392 0.82730392 0.82730392 0.82730392 0.82730392 0.82730392])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward on Test Set: 16.0\n",
      "Total Profit on Test Set: 245.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_activ_count</td><td>â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–ˆâ–</td></tr><tr><td>step_activ_ratio</td><td>â–â–â–â–†â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–†â–ˆâ–</td></tr><tr><td>step_lost_count</td><td>â–ƒâ–ƒâ–…â–ƒâ–…â–†â–…â–â–…â–ƒâ–ƒâ–†â–…â–…â–…â–†â–ƒâ–†â–†â–…â–…â–ƒâ–ƒâ–†â–…â–†â–†â–ƒâ–ƒâ–†â–…â–ƒâ–ˆâ–†â–…â–…â–ƒâ–ƒâ–â–ƒ</td></tr><tr><td>step_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_part_count</td><td>â–†â–ˆâ–ƒâ–†â–ƒâ–ƒâ–ƒâ–â–â–ˆâ–ƒâ–â–†â–ƒâ–ƒâ–ƒâ–†â–â–ƒâ–ƒâ–â–ƒâ–â–â–†â–ƒâ–â–ƒâ–â–ƒâ–â–â–â–ƒâ–ƒâ–ƒâ–†â–ƒâ–†â–ˆ</td></tr><tr><td>step_not_res_count</td><td>â–ƒâ–â–ƒâ–â–ƒâ–â–ƒâ–ˆâ–†â–â–†â–ƒâ–â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–ƒâ–†â–†â–ˆâ–ƒâ–â–â–ƒâ–†â–ˆâ–â–ƒâ–ˆâ–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–</td></tr><tr><td>step_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–…â–‡â–ˆâ–ˆâ–‡â–ˆâ–†â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–†â–†â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–‚â–†â–ˆâ–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–†â–ˆâ–ˆ</td></tr><tr><td>step_profit</td><td>â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–‚â–ˆâ–</td></tr><tr><td>step_res_count</td><td>â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–ˆâ–</td></tr><tr><td>step_res_ratio</td><td>â–â–â–â–ˆâ–â–â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–‡â–ˆâ–</td></tr><tr><td>step_revenue</td><td>â–â–â–â–â–â–â–â–ˆâ–â–â–â–‚â–â–‚â–â–â–â–â–â–‚â–‚â–„â–‚â–‚â–â–â–â–†â–ƒâ–â–…â–ƒâ–â–â–â–â–â–‚â–ƒâ–</td></tr><tr><td>step_reward</td><td>â–ƒâ–ƒâ–ƒâ–†â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–„â–„â–†â–ƒâ–‚â–â–„â–„â–…â–‚â–‡â–…â–â–‚â–ƒâ–ƒâ–ƒâ–†â–†â–ƒ</td></tr><tr><td>step_won_count</td><td>â–ƒâ–â–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–…â–â–…â–ƒâ–â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–ƒâ–…â–…â–†â–ƒâ–â–â–ƒâ–…â–†â–â–…â–†â–â–â–ƒâ–ƒâ–ƒâ–…â–…â–</td></tr><tr><td>step_won_ratio</td><td>â–ƒâ–â–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–…â–â–…â–ƒâ–â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–ƒâ–…â–…â–†â–ƒâ–â–â–ƒâ–…â–†â–â–…â–†â–â–â–ƒâ–ƒâ–ƒâ–…â–…â–</td></tr><tr><td>total_activ_count</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_lost_count</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>total_not_part_count</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_res_count</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>total_profit</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_profit_test</td><td>â–</td></tr><tr><td>total_res_count</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_revenue</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_reward</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_reward_test</td><td>â–</td></tr><tr><td>total_won_count</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2785</td></tr><tr><td>step_activ_count</td><td>0</td></tr><tr><td>step_activ_ratio</td><td>0.0</td></tr><tr><td>step_lost_count</td><td>4</td></tr><tr><td>step_not_activ_count</td><td>0</td></tr><tr><td>step_not_part_count</td><td>1</td></tr><tr><td>step_not_res_count</td><td>1</td></tr><tr><td>step_penalties</td><td>-1786.58154</td></tr><tr><td>step_profit</td><td>0.0</td></tr><tr><td>step_res_count</td><td>0</td></tr><tr><td>step_res_ratio</td><td>0.0</td></tr><tr><td>step_revenue</td><td>58.0</td></tr><tr><td>step_reward</td><td>0.15495</td></tr><tr><td>step_won_count</td><td>1</td></tr><tr><td>step_won_ratio</td><td>0.16667</td></tr><tr><td>total_activ_count</td><td>374</td></tr><tr><td>total_lost_count</td><td>10652</td></tr><tr><td>total_not_activ_count</td><td>0</td></tr><tr><td>total_not_part_count</td><td>3474</td></tr><tr><td>total_not_res_count</td><td>2216</td></tr><tr><td>total_penalties</td><td>-1413372.81563</td></tr><tr><td>total_profit</td><td>46666.53244</td></tr><tr><td>total_profit_test</td><td>245.2</td></tr><tr><td>total_res_count</td><td>374</td></tr><tr><td>total_revenue</td><td>352429.42</td></tr><tr><td>total_reward</td><td>452.74626</td></tr><tr><td>total_reward_test</td><td>16.0</td></tr><tr><td>total_won_count</td><td>2590</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20221127_130705-2i5dvf26<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221127_130705-2i5dvf26/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-optuna/runs/2i5dvf26 ... done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 13:16:36,265]\u001b[0m Trial 0 finished with value: 16.0 and parameters: {'learning_rate': 7.890447483613503e-05, 'batch_size': 100, 'buffer_size': 10000, 'tau': 0.005, 'gamma': 0.99, 'train_freq': 2, 'gradient_steps': 8, 'learning_starts': 200, 'noise_type': 'normal', 'noise_std': 0.8273039240631445, 'policy_delay': 5, 'target_policy_noise': 0.3, 'ent_coef': 0.5, 'target_entropy': -10, 'net_arch': 'medium', 'use_sde': False, 'activation_fn': 'relu'}. Best is trial 0 with value: 16.0.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 13:16:36,269]\u001b[0m A new study created in memory with name: no-name-4e1e875d-2f47-4536-840a-8972faebf82f\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning : DDPG\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe94c41f4d74812b0301182aaed6745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 7.68601283871745e-05, 'buffer_size': 10000, 'learning_starts': 20, 'batch_size': 200, 'tau': 0.001, 'gamma': 0.95, 'train_freq': 1, 'gradient_steps': 32, 'policy_kwargs': {'net_arch': [64, 64], 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'n_critics': 1}, 'action_noise': OrnsteinUhlenbeckActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.73242759 0.73242759 0.73242759 0.73242759 0.73242759 0.73242759\n",
      " 0.73242759 0.73242759 0.73242759 0.73242759 0.73242759 0.73242759])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward on Test Set: 58.73\n",
      "Total Profit on Test Set: 8098.66\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–ƒâ–â–ƒâ–â–†â–†â–â–â–â–ˆâ–â–â–â–â–â–â–ƒâ–ˆâ–</td></tr><tr><td>step_activ_ratio</td><td>â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–ˆâ–â–ˆâ–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–ˆâ–</td></tr><tr><td>step_lost_count</td><td>â–ˆâ–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_part_count</td><td>â–â–…â–…â–…â–…â–…â–…â–ˆâ–ˆâ–ˆâ–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–…â–…â–ˆâ–…â–…â–ˆâ–ˆâ–…â–…â–…â–…â–…â–â–â–…â–…â–â–…â–ˆâ–â–</td></tr><tr><td>step_not_res_count</td><td>â–…â–†â–†â–†â–†â–†â–†â–…â–…â–…â–ƒâ–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–ƒâ–†â–…â–…â–â–ƒâ–†â–†â–†â–â–ˆâ–ˆâ–†â–†â–ˆâ–†â–ƒâ–ƒâ–ˆ</td></tr><tr><td>step_penalties</td><td>â–‡â–†â–†â–†â–†â–„â–â–†â–‡â–‡â–ˆâ–†â–†â–„â–†â–„â–‡â–‡â–‡â–†â–…â–†â–†â–…â–ˆâ–ˆâ–ˆâ–…â–†â–„â–„â–„â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–ƒ</td></tr><tr><td>step_profit</td><td>â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–ƒâ–â–â–â–â–â–â–ƒâ–â–‚â–â–ƒâ–‚â–â–â–â–ˆâ–â–â–â–‚â–â–â–‡â–ˆâ–</td></tr><tr><td>step_res_count</td><td>â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–ƒâ–â–ƒâ–â–†â–†â–â–â–â–ˆâ–â–â–â–â–â–â–ƒâ–ˆâ–</td></tr><tr><td>step_res_ratio</td><td>â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–„â–â–ƒâ–â–‡â–†â–â–â–â–ˆâ–â–â–â–â–â–â–„â–‡â–</td></tr><tr><td>step_revenue</td><td>â–‚â–ƒâ–‚â–†â–‡â–„â–†â–†â–â–‚â–â–„â–ƒâ–†â–…â–…â–â–‚â–‚â–„â–ƒâ–‡â–…â–„â–â–â–â–ˆâ–„â–†â–…â–…â–‚â–ƒâ–â–‚â–ƒâ–„â–‡â–‚</td></tr><tr><td>step_reward</td><td>â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–…â–†â–ƒâ–ƒâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ˆâ–„</td></tr><tr><td>step_won_count</td><td>â–â–…â–…â–…â–…â–…â–…â–â–â–â–â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–â–â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–…â–ˆâ–…â–â–ˆâ–ˆ</td></tr><tr><td>step_won_ratio</td><td>â–â–…â–…â–…â–…â–…â–…â–â–â–â–â–…â–…â–â–…â–…â–…â–…â–…â–…â–…â–â–…â–…â–â–â–…â–…â–…â–…â–…â–ˆâ–ˆâ–…â–…â–ˆâ–…â–â–ˆâ–ˆ</td></tr><tr><td>total_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_lost_count</td><td>â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>total_not_part_count</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_res_count</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–</td></tr><tr><td>total_profit</td><td>â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆ</td></tr><tr><td>total_profit_test</td><td>â–</td></tr><tr><td>total_res_count</td><td>â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_revenue</td><td>â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_reward</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_reward_test</td><td>â–</td></tr><tr><td>total_won_count</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2784</td></tr><tr><td>step_activ_count</td><td>0</td></tr><tr><td>step_activ_ratio</td><td>0</td></tr><tr><td>step_lost_count</td><td>0</td></tr><tr><td>step_not_activ_count</td><td>0</td></tr><tr><td>step_not_part_count</td><td>3</td></tr><tr><td>step_not_res_count</td><td>3</td></tr><tr><td>step_penalties</td><td>-5769.72786</td></tr><tr><td>step_profit</td><td>0.0</td></tr><tr><td>step_res_count</td><td>0</td></tr><tr><td>step_res_ratio</td><td>0.0</td></tr><tr><td>step_revenue</td><td>201.24</td></tr><tr><td>step_reward</td><td>0.32025</td></tr><tr><td>step_won_count</td><td>3</td></tr><tr><td>step_won_ratio</td><td>0.5</td></tr><tr><td>total_activ_count</td><td>1095</td></tr><tr><td>total_lost_count</td><td>593</td></tr><tr><td>total_not_activ_count</td><td>0</td></tr><tr><td>total_not_part_count</td><td>5814</td></tr><tr><td>total_not_res_count</td><td>9208</td></tr><tr><td>total_penalties</td><td>-5924435.85712</td></tr><tr><td>total_profit</td><td>139910.85311</td></tr><tr><td>total_profit_test</td><td>8098.66</td></tr><tr><td>total_res_count</td><td>1095</td></tr><tr><td>total_revenue</td><td>1294189.18</td></tr><tr><td>total_reward</td><td>981.19423</td></tr><tr><td>total_reward_test</td><td>58.73</td></tr><tr><td>total_won_count</td><td>10303</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20221127_131636-kjlt8xbx<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221127_131636-kjlt8xbx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-optuna/runs/kjlt8xbx ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 13:40:05,929]\u001b[0m Trial 0 finished with value: 58.73 and parameters: {'learning_rate': 7.68601283871745e-05, 'buffer_size': 10000, 'learning_starts': 20, 'batch_size': 200, 'tau': 0.001, 'gamma': 0.95, 'train_freq': 1, 'gradient_steps': 32, 'noise_type': 'ornstein-uhlenbeck', 'noise_std': 0.7324275872798359, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 0 with value: 58.73.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 13:40:05,940]\u001b[0m A new study created in memory with name: no-name-f289cff3-5cd1-4f56-9040-dacc610d2a26\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning : TD3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acd17255c81b47288fba8beb73dde978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0002032456346988182, 'batch_size': 64, 'buffer_size': 100000, 'tau': 0.01, 'gamma': 0.9, 'train_freq': 1, 'gradient_steps': 2, 'learning_starts': 20, 'policy_delay': 1, 'target_policy_noise': 0.2, 'policy_kwargs': {'net_arch': [400, 300], 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward on Test Set: 39.73\n",
      "Total Profit on Test Set: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_activ_ratio</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_lost_count</td><td>â–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_part_count</td><td>â–…â–ˆâ–ˆâ–…â–…â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_res_count</td><td>â–ƒâ–â–ƒâ–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_penalties</td><td>â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–…â–†â–‡â–‡â–ˆâ–‡â–†â–…â–‡â–ƒâ–‡â–‡â–‡â–‡â–…â–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–†â–‡â–„â–â–…â–ˆâ–‡â–‡â–‡â–…â–†â–‡â–ƒ</td></tr><tr><td>step_profit</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_res_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_res_ratio</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_revenue</td><td>â–â–â–â–ƒâ–ƒâ–‚â–„â–†â–‚â–ƒâ–‚â–…â–„â–†â–„â–†â–‚â–‚â–‚â–„â–„â–…â–„â–„â–‚â–ƒâ–‚â–ˆâ–„â–…â–‡â–…â–ƒâ–„â–‚â–ƒâ–„â–…â–‡â–ƒ</td></tr><tr><td>step_reward</td><td>â–†â–â–‚â–„â–…â–…â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_won_count</td><td>â–ƒâ–â–ƒâ–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_won_ratio</td><td>â–ƒâ–â–ƒâ–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_activ_count</td><td>â–â–â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_lost_count</td><td>â–â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>total_not_part_count</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_res_count</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>total_profit</td><td>â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_profit_test</td><td>â–</td></tr><tr><td>total_res_count</td><td>â–â–â–…â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_revenue</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_reward</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_reward_test</td><td>â–</td></tr><tr><td>total_won_count</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2784</td></tr><tr><td>step_activ_count</td><td>0</td></tr><tr><td>step_activ_ratio</td><td>0</td></tr><tr><td>step_lost_count</td><td>0</td></tr><tr><td>step_not_activ_count</td><td>0</td></tr><tr><td>step_not_part_count</td><td>2</td></tr><tr><td>step_not_res_count</td><td>4</td></tr><tr><td>step_penalties</td><td>-11979.82279</td></tr><tr><td>step_profit</td><td>0.0</td></tr><tr><td>step_res_count</td><td>0</td></tr><tr><td>step_res_ratio</td><td>0.0</td></tr><tr><td>step_revenue</td><td>389.64</td></tr><tr><td>step_reward</td><td>0.29561</td></tr><tr><td>step_won_count</td><td>4</td></tr><tr><td>step_won_ratio</td><td>0.66667</td></tr><tr><td>total_activ_count</td><td>10</td></tr><tr><td>total_lost_count</td><td>269</td></tr><tr><td>total_not_activ_count</td><td>0</td></tr><tr><td>total_not_part_count</td><td>6029</td></tr><tr><td>total_not_res_count</td><td>10402</td></tr><tr><td>total_penalties</td><td>-11315609.5104</td></tr><tr><td>total_profit</td><td>1863.66041</td></tr><tr><td>total_profit_test</td><td>0.0</td></tr><tr><td>total_res_count</td><td>10</td></tr><tr><td>total_revenue</td><td>1810442.23</td></tr><tr><td>total_reward</td><td>769.86294</td></tr><tr><td>total_reward_test</td><td>39.73</td></tr><tr><td>total_won_count</td><td>10412</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20221127_134005-22g4trpv<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221127_134005-22g4trpv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-optuna/runs/22g4trpv ... done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 13:48:05,201]\u001b[0m Trial 0 finished with value: 39.73 and parameters: {'learning_rate': 0.0002032456346988182, 'batch_size': 64, 'buffer_size': 100000, 'tau': 0.01, 'gamma': 0.9, 'train_freq': 1, 'gradient_steps': 2, 'learning_starts': 20, 'noise_type': None, 'noise_std': 0.9702660909103161, 'policy_delay': 1, 'target_policy_noise': 0.2, 'net_arch': 'big', 'activation_fn': 'relu'}. Best is trial 0 with value: 39.73.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 13:48:05,205]\u001b[0m A new study created in memory with name: no-name-d851ea4a-ecf4-47e6-bffd-4e28e0d00398\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning : TRPO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49592b18ed1e4c7aad4f0e9bda205495",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.00021194496512660276, 'n_steps': 9, 'batch_size': 9, 'gamma': 0.999, 'cg_max_steps': 30, 'cg_damping': 0.01, 'line_search_shrinking_factor': 0.9, 'line_search_max_iter': 10, 'n_critic_updates': 5, 'gae_lambda': 0.8, 'normalize_advantage': True, 'use_sde': False, 'target_kl': 0.03, 'policy_kwargs': {'net_arch': [{'pi': [400, 400], 'vf': [400, 400]}], 'ortho_init': True, 'activation_fn': <class 'torch.nn.modules.activation.LeakyReLU'>}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward on Test Set: 56.2\n",
      "Total Profit on Test Set: 4698.51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "039ac2c2431b4e9695ada55d0ff18398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_activ_count</td><td>â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–…â–â–â–â–â–…â–â–â–â–â–â–â–â–…â–</td></tr><tr><td>step_activ_ratio</td><td>â–â–â–â–†â–â–â–â–†â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–ƒâ–â–â–â–â–ˆâ–â–â–â–â–â–â–â–…â–</td></tr><tr><td>step_lost_count</td><td>â–ˆâ–†â–†â–ƒâ–ƒâ–ƒâ–â–ƒâ–â–â–ˆâ–ƒâ–â–â–â–â–â–â–â–†â–â–ˆâ–â–â–ƒâ–†â–†â–â–â–â–â–â–â–â–ƒâ–â–â–ƒâ–ƒâ–</td></tr><tr><td>step_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_part_count</td><td>â–†â–…â–ˆâ–…â–…â–…â–ƒâ–â–ƒâ–â–â–ƒâ–…â–â–â–ƒâ–†â–ƒâ–ƒâ–â–…â–â–…â–â–â–â–â–…â–ƒâ–…â–â–ƒâ–â–â–â–â–â–â–ƒâ–…</td></tr><tr><td>step_not_res_count</td><td>â–â–ƒâ–â–‚â–…â–…â–‡â–…â–‡â–ˆâ–ƒâ–†â–†â–ˆâ–ˆâ–‡â–…â–‡â–‡â–†â–†â–…â–†â–†â–‡â–…â–†â–†â–‡â–†â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–…â–†</td></tr><tr><td>step_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–‡â–‡â–‡â–ˆâ–‡â–‡â–„â–†â–„â–ˆâ–‡â–‡â–‡â–†â–‡â–‡â–†â–‡â–ˆâ–ˆâ–†â–†â–„â–â–…â–‡â–‡â–‡â–‡â–…â–‡â–‡â–ƒ</td></tr><tr><td>step_profit</td><td>â–â–â–â–…â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–†â–‡â–</td></tr><tr><td>step_res_count</td><td>â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–…â–â–â–â–â–…â–â–â–â–â–â–â–â–…â–</td></tr><tr><td>step_res_ratio</td><td>â–â–â–â–ˆâ–â–â–â–†â–â–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–ƒâ–â–â–â–â–ƒâ–â–â–â–â–â–â–â–„â–</td></tr><tr><td>step_revenue</td><td>â–â–â–â–‚â–‚â–‚â–ƒâ–…â–‚â–ƒâ–â–ƒâ–‚â–…â–„â–„â–â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–…â–‚â–‚â–‚â–…â–ƒâ–†â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–‚</td></tr><tr><td>step_reward</td><td>â–‚â–ƒâ–â–†â–„â–„â–…â–ˆâ–„â–…â–„â–„â–„â–…â–†â–…â–„â–„â–…â–„â–„â–„â–„â–ˆâ–„â–†â–…â–„â–„â–„â–‡â–„â–…â–…â–…â–…â–…â–†â–†â–„</td></tr><tr><td>step_won_count</td><td>â–â–ƒâ–â–…â–…â–…â–‡â–‡â–‡â–ˆâ–…â–†â–†â–ˆâ–ˆâ–‡â–…â–‡â–‡â–†â–†â–…â–†â–ˆâ–‡â–†â–†â–†â–‡â–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–†â–†</td></tr><tr><td>step_won_ratio</td><td>â–â–ƒâ–â–…â–…â–…â–‡â–‡â–‡â–ˆâ–…â–†â–†â–ˆâ–ˆâ–‡â–…â–‡â–‡â–†â–†â–…â–†â–ˆâ–‡â–†â–†â–†â–‡â–†â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–ˆâ–‡â–†â–†</td></tr><tr><td>total_activ_count</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_lost_count</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>total_not_part_count</td><td>â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_res_count</td><td>â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–</td></tr><tr><td>total_profit</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_profit_test</td><td>â–</td></tr><tr><td>total_res_count</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_revenue</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_reward</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_reward_test</td><td>â–</td></tr><tr><td>total_won_count</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2789</td></tr><tr><td>step_activ_count</td><td>0</td></tr><tr><td>step_activ_ratio</td><td>0.0</td></tr><tr><td>step_lost_count</td><td>1</td></tr><tr><td>step_not_activ_count</td><td>0</td></tr><tr><td>step_not_part_count</td><td>1</td></tr><tr><td>step_not_res_count</td><td>4</td></tr><tr><td>step_penalties</td><td>-1496.84781</td></tr><tr><td>step_profit</td><td>0.0</td></tr><tr><td>step_res_count</td><td>0</td></tr><tr><td>step_res_ratio</td><td>0.0</td></tr><tr><td>step_revenue</td><td>168.92</td></tr><tr><td>step_reward</td><td>0.31821</td></tr><tr><td>step_won_count</td><td>4</td></tr><tr><td>step_won_ratio</td><td>0.66667</td></tr><tr><td>total_activ_count</td><td>976</td></tr><tr><td>total_lost_count</td><td>2202</td></tr><tr><td>total_not_activ_count</td><td>0</td></tr><tr><td>total_not_part_count</td><td>3035</td></tr><tr><td>total_not_res_count</td><td>10527</td></tr><tr><td>total_penalties</td><td>-7679109.33194</td></tr><tr><td>total_profit</td><td>125438.72881</td></tr><tr><td>total_profit_test</td><td>4698.51</td></tr><tr><td>total_res_count</td><td>976</td></tr><tr><td>total_revenue</td><td>1583184.62</td></tr><tr><td>total_reward</td><td>999.64048</td></tr><tr><td>total_reward_test</td><td>56.2</td></tr><tr><td>total_won_count</td><td>11503</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20221127_134805-37zdozo5<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221127_134805-37zdozo5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-optuna/runs/37zdozo5 ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 13:53:59,384]\u001b[0m Trial 0 finished with value: 56.2 and parameters: {'learning_rate': 0.00021194496512660276, 'n_steps': 9, 'batch_size': 64, 'gamma': 0.999, 'cg_max_steps': 30, 'cg_damping': 0.01, 'line_search_shrinking_factor': 0.9, 'line_search_max_iter': 10, 'n_critic_updates': 5, 'gae_lambda': 0.8, 'normalize_advantage': True, 'use_sde': False, 'target_kl': 0.03, 'sde_net_arch': None, 'lr_schedule': 'constant', 'net_arch': 'big', 'ortho_init': True, 'activation_fn': 'leaky_relu'}. Best is trial 0 with value: 56.2.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 13:53:59,386]\u001b[0m A new study created in memory with name: no-name-5accc99c-882c-4894-9128-6b25e428e485\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Now tuning : R_PPO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a385fa4cf84e5d976877721d6f68df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.00013080881703724878, 'n_steps': 7, 'batch_size': 7, 'n_epochs': 20, 'gamma': 0.9, 'gae_lambda': 0.7, 'clip_range': 0.3, 'normalize_advantage': True, 'ent_coef': 0.002289933363195296, 'vf_coef': 0.5667657642583892, 'max_grad_norm': 0.3, 'target_kl': 0.02, 'policy_kwargs': {'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}], 'full_std': True, 'activation_fn': <class 'torch.nn.modules.activation.Tanh'>, 'ortho_init': False}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward on Test Set: 65.69\n",
      "Total Profit on Test Set: 4880.2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf73d5ea4cec4cf7a06896f71e872b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_activ_count</td><td>â–â–â–ƒâ–ƒâ–â–â–â–ƒâ–â–â–…â–â–â–â–â–â–â–â–â–â–â–†â–â–…â–â–…â–…â–â–â–â–ƒâ–â–â–â–â–â–â–†â–ˆâ–</td></tr><tr><td>step_activ_ratio</td><td>â–â–â–‚â–…â–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–ˆâ–â–ˆâ–â–†â–ˆâ–â–â–â–ˆâ–â–â–â–â–â–â–ˆâ–ˆâ–</td></tr><tr><td>step_lost_count</td><td>â–ˆâ–…â–‡â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_part_count</td><td>â–â–ˆâ–â–…â–…â–â–…â–ˆâ–…â–â–â–ˆâ–ˆâ–…â–…â–ˆâ–ˆâ–…â–…â–…â–â–…â–…â–â–â–â–ˆâ–â–…â–â–…â–…â–…â–…â–…â–…â–…â–…â–…â–ˆ</td></tr><tr><td>step_not_res_count</td><td>â–â–â–â–„â–…â–ˆâ–‡â–„â–…â–‡â–…â–„â–„â–‡â–‡â–…â–…â–‡â–‡â–‡â–ˆâ–‚â–‡â–…â–ˆâ–„â–‚â–ˆâ–‡â–ˆâ–…â–‡â–‡â–‡â–‡â–‡â–‡â–‚â–â–…</td></tr><tr><td>step_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–…â–…â–‡â–ˆâ–‡â–ˆâ–‡â–‡â–„â–‡â–„â–‡â–ˆâ–ˆâ–‡â–…â–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–„â–‡â–„â–â–‡â–ˆâ–‡â–‡â–ˆâ–†â–‡â–ˆâ–„</td></tr><tr><td>step_profit</td><td>â–â–â–â–‚â–â–â–â–‚â–â–â–‚â–â–â–â–ƒâ–â–â–â–â–‚â–â–…â–â–ƒâ–â–‚â–‚â–â–â–â–ƒâ–â–â–â–â–â–â–ƒâ–ˆâ–</td></tr><tr><td>step_res_count</td><td>â–â–â–ƒâ–ƒâ–â–â–â–ƒâ–â–â–…â–â–â–â–â–â–â–â–â–â–â–†â–â–…â–â–…â–…â–â–â–â–ƒâ–â–â–â–â–â–â–†â–ˆâ–</td></tr><tr><td>step_res_ratio</td><td>â–â–â–‚â–ƒâ–â–â–â–ƒâ–â–â–„â–â–â–â–â–â–â–â–â–â–â–†â–â–„â–â–„â–…â–â–â–â–ƒâ–â–â–â–â–â–â–†â–ˆâ–</td></tr><tr><td>step_revenue</td><td>â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–‚â–‚â–ƒâ–‚â–…â–ƒâ–„â–‚â–â–â–ƒâ–„â–„â–ƒâ–„â–‚â–‚â–â–ˆâ–‚â–„â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–‚</td></tr><tr><td>step_reward</td><td>â–â–‚â–ƒâ–„â–ƒâ–„â–„â–„â–ƒâ–„â–‡â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–„â–‡â–„â–‡â–…â–†â–…â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–‡â–ˆâ–ƒ</td></tr><tr><td>step_won_count</td><td>â–â–â–‚â–…â–…â–ˆâ–‡â–…â–…â–‡â–ˆâ–„â–„â–‡â–‡â–…â–…â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–…â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…</td></tr><tr><td>step_won_ratio</td><td>â–â–â–‚â–…â–…â–ˆâ–‡â–…â–…â–‡â–ˆâ–„â–„â–‡â–‡â–…â–…â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–‡â–…â–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–…</td></tr><tr><td>total_activ_count</td><td>â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_lost_count</td><td>â–â–‚â–ƒâ–„â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>total_not_part_count</td><td>â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_res_count</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>total_profit</td><td>â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_profit_test</td><td>â–</td></tr><tr><td>total_res_count</td><td>â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_revenue</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_reward</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_reward_test</td><td>â–</td></tr><tr><td>total_won_count</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2785</td></tr><tr><td>step_activ_count</td><td>0</td></tr><tr><td>step_activ_ratio</td><td>0</td></tr><tr><td>step_lost_count</td><td>0</td></tr><tr><td>step_not_activ_count</td><td>0</td></tr><tr><td>step_not_part_count</td><td>2</td></tr><tr><td>step_not_res_count</td><td>4</td></tr><tr><td>step_penalties</td><td>-9399.08193</td></tr><tr><td>step_profit</td><td>0.0</td></tr><tr><td>step_res_count</td><td>0</td></tr><tr><td>step_res_ratio</td><td>0.0</td></tr><tr><td>step_revenue</td><td>362.6</td></tr><tr><td>step_reward</td><td>0.30648</td></tr><tr><td>step_won_count</td><td>4</td></tr><tr><td>step_won_ratio</td><td>0.66667</td></tr><tr><td>total_activ_count</td><td>1442</td></tr><tr><td>total_lost_count</td><td>1397</td></tr><tr><td>total_not_activ_count</td><td>0</td></tr><tr><td>total_not_part_count</td><td>2858</td></tr><tr><td>total_not_res_count</td><td>11019</td></tr><tr><td>total_penalties</td><td>-7624877.89741</td></tr><tr><td>total_profit</td><td>160427.09917</td></tr><tr><td>total_profit_test</td><td>4880.2</td></tr><tr><td>total_res_count</td><td>1442</td></tr><tr><td>total_revenue</td><td>1610950.69</td></tr><tr><td>total_reward</td><td>1092.4839</td></tr><tr><td>total_reward_test</td><td>65.69</td></tr><tr><td>total_won_count</td><td>12461</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20221127_135359-1mys0726<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221127_135359-1mys0726/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-optuna/runs/1mys0726 ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 14:00:36,677]\u001b[0m Trial 0 finished with value: 65.69 and parameters: {'learning_rate': 0.00013080881703724878, 'n_steps': 7, 'batch_size': 200, 'n_epochs': 20, 'gamma': 0.9, 'gae_lambda': 0.7, 'clip_range': 0.3, 'normalize_advantage': True, 'ent_coef': 0.002289933363195296, 'vf_coef': 0.5667657642583892, 'max_grad_norm': 0.3, 'target_kl': 0.02, 'lr_schedule': 'constant', 'use_sde': False, 'full_std': True, 'activation_fn': 'tanh', 'ortho_init': False, 'net_arch': 'small'}. Best is trial 0 with value: 65.69.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 14:00:36,679]\u001b[0m A new study created in memory with name: no-name-c0083d0b-99a0-4638-92bc-29d4124b3790\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Now tuning : A2C\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0a2c60752e48e28487b32239d93cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 8, 'gamma': 0.9999, 'gae_lambda': 0.7, 'learning_rate': 0.006140935435263496, 'ent_coef': 1e-08, 'normalize_advantage': True, 'max_grad_norm': 5, 'use_rms_prop': False, 'use_sde': False, 'vf_coef': 0.7650497492382338, 'policy_kwargs': {'net_arch': [{'pi': [64, 64], 'vf': [64, 64]}], 'full_std': True, 'activation_fn': <class 'torch.nn.modules.activation.ELU'>, 'sde_net_arch': [64], 'ortho_init': False}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward on Test Set: 46.19\n",
      "Total Profit on Test Set: 335.29\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8600e28b1441a7bb99f50cb400af89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_activ_count</td><td>â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_activ_ratio</td><td>â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_lost_count</td><td>â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–ˆâ–ˆâ–â–…â–â–â–â–…â–â–…â–â–â–…â–ˆâ–</td></tr><tr><td>step_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_part_count</td><td>â–†â–†â–…â–ƒâ–â–…â–…â–ˆâ–†â–…â–†â–ƒâ–…â–…â–†â–…â–†â–†â–…â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–…â–…â–…â–â–â–â–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–†â–†â–</td></tr><tr><td>step_not_res_count</td><td>â–„â–„â–…â–„â–ˆâ–…â–…â–â–„â–…â–„â–‡â–…â–…â–„â–…â–„â–„â–…â–‡â–‡â–…â–‡â–ˆâ–‡â–‚â–‚â–…â–‡â–ˆâ–‡â–‡â–„â–…â–…â–‡â–‡â–‚â–â–ˆ</td></tr><tr><td>step_penalties</td><td>â–ˆâ–ˆâ–ˆâ–‡â–‡â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–†â–†â–…â–‡â–„â–ˆâ–‡â–ˆâ–‡â–…â–‡â–‡â–…â–ˆâ–ˆâ–ˆâ–†â–†â–ƒâ–â–…â–ˆâ–ˆâ–‡â–‡â–…â–‡â–ˆâ–ƒ</td></tr><tr><td>step_profit</td><td>â–â–â–â–‡â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_res_count</td><td>â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_res_ratio</td><td>â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–„â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_revenue</td><td>â–â–â–â–„â–…â–‚â–ƒâ–‚â–â–‚â–â–„â–ƒâ–…â–‚â–…â–â–â–â–ƒâ–„â–…â–„â–†â–‚â–â–â–†â–„â–†â–ˆâ–„â–â–‚â–â–ƒâ–ƒâ–ƒâ–‚â–ƒ</td></tr><tr><td>step_reward</td><td>â–ƒâ–„â–„â–ˆâ–†â–„â–„â–â–ƒâ–„â–ƒâ–„â–„â–„â–ƒâ–„â–„â–„â–„â–…â–„â–„â–„â–†â–„â–‚â–‚â–„â–…â–…â–‡â–…â–„â–…â–„â–„â–…â–‚â–â–…</td></tr><tr><td>step_won_count</td><td>â–„â–„â–…â–‡â–ˆâ–…â–…â–â–„â–…â–„â–‡â–…â–…â–„â–…â–„â–„â–…â–‡â–‡â–…â–‡â–ˆâ–‡â–‚â–‚â–…â–‡â–ˆâ–ˆâ–‡â–„â–…â–…â–‡â–‡â–‚â–â–ˆ</td></tr><tr><td>step_won_ratio</td><td>â–„â–„â–…â–‡â–ˆâ–…â–…â–â–„â–…â–„â–‡â–…â–…â–„â–…â–„â–„â–…â–‡â–‡â–…â–‡â–ˆâ–‡â–‚â–‚â–…â–‡â–ˆâ–ˆâ–‡â–„â–…â–…â–‡â–‡â–‚â–â–ˆ</td></tr><tr><td>total_activ_count</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_lost_count</td><td>â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>total_not_part_count</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_res_count</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>total_profit</td><td>â–â–â–â–â–â–â–‚â–ƒâ–„â–„â–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_profit_test</td><td>â–</td></tr><tr><td>total_res_count</td><td>â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_revenue</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_reward</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_reward_test</td><td>â–</td></tr><tr><td>total_won_count</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2791</td></tr><tr><td>step_activ_count</td><td>0</td></tr><tr><td>step_activ_ratio</td><td>0</td></tr><tr><td>step_lost_count</td><td>0</td></tr><tr><td>step_not_activ_count</td><td>0</td></tr><tr><td>step_not_part_count</td><td>1</td></tr><tr><td>step_not_res_count</td><td>5</td></tr><tr><td>step_penalties</td><td>-2357.1626</td></tr><tr><td>step_profit</td><td>0.0</td></tr><tr><td>step_res_count</td><td>0</td></tr><tr><td>step_res_ratio</td><td>0.0</td></tr><tr><td>step_revenue</td><td>237.09</td></tr><tr><td>step_reward</td><td>0.30289</td></tr><tr><td>step_won_count</td><td>5</td></tr><tr><td>step_won_ratio</td><td>0.83333</td></tr><tr><td>total_activ_count</td><td>276</td></tr><tr><td>total_lost_count</td><td>851</td></tr><tr><td>total_not_activ_count</td><td>0</td></tr><tr><td>total_not_part_count</td><td>4581</td></tr><tr><td>total_not_res_count</td><td>11044</td></tr><tr><td>total_penalties</td><td>-11387752.64483</td></tr><tr><td>total_profit</td><td>27790.45938</td></tr><tr><td>total_profit_test</td><td>335.29</td></tr><tr><td>total_res_count</td><td>276</td></tr><tr><td>total_revenue</td><td>1989273.57</td></tr><tr><td>total_reward</td><td>820.04116</td></tr><tr><td>total_reward_test</td><td>46.19</td></tr><tr><td>total_won_count</td><td>11320</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20221127_140036-ov3s01p0<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221127_140036-ov3s01p0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-optuna/runs/ov3s01p0 ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 14:05:58,632]\u001b[0m Trial 0 finished with value: 46.19 and parameters: {'gamma': 0.9999, 'normalize_advantage': True, 'max_grad_norm': 5, 'use_rms_prop': False, 'gae_lambda': 0.7, 'n_steps': 8, 'learning_rate': 0.006140935435263496, 'ent_coef': 1e-08, 'vf_coef': 0.7650497492382338, 'lr_schedule': 'constant', 'use_sde': False, 'sde_net_arch': 'tiny', 'full_std': True, 'activation_fn': 'elu', 'ortho_init': False, 'net_arch': 'small'}. Best is trial 0 with value: 46.19.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 14:05:58,634]\u001b[0m A new study created in memory with name: no-name-488562b4-57a8-4235-bfd6-e64103337856\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Now tuning : PPO\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159ebcbc488548c8bee71d521afdf304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.0005848158439951756, 'n_steps': 3, 'batch_size': 3, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.98, 'clip_range': 0.1, 'normalize_advantage': True, 'ent_coef': 0.0009728015659605418, 'vf_coef': 0.9541487034869848, 'max_grad_norm': 0.7, 'use_sde': False, 'target_kl': 0.03, 'policy_kwargs': {'net_arch': [{'pi': [400, 400], 'vf': [400, 400]}], 'ortho_init': True, 'activation_fn': <class 'torch.nn.modules.activation.ELU'>}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward on Test Set: 43.76\n",
      "Total Profit on Test Set: 512.12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1a25b847dd429bb39fc869ee7a03e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_activ_count</td><td>â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_activ_ratio</td><td>â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_lost_count</td><td>â–ƒâ–ƒâ–†â–†â–ˆâ–â–†â–†â–â–â–†â–†â–ƒâ–ƒâ–â–ƒâ–â–â–†â–ƒâ–â–†â–â–â–â–ƒâ–†â–â–â–â–â–â–â–â–â–â–â–†â–ƒâ–</td></tr><tr><td>step_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_part_count</td><td>â–ˆâ–†â–…â–ƒâ–†â–†â–†â–ƒâ–†â–†â–ƒâ–†â–†â–†â–…â–†â–…â–…â–ƒâ–ƒâ–…â–â–…â–…â–†â–â–â–†â–…â–…â–…â–…â–…â–†â–†â–…â–…â–â–†â–ƒ</td></tr><tr><td>step_not_res_count</td><td>â–‚â–„â–„â–„â–â–…â–‚â–„â–…â–…â–„â–‚â–„â–„â–‡â–„â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–…â–…â–‡â–‡â–‡â–‡â–‡â–…â–…â–‡â–‡â–‡â–„â–ˆ</td></tr><tr><td>step_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–†â–‡â–†â–‡â–‡â–‡â–‡â–†â–‡â–‡â–†â–ˆâ–ˆâ–ˆâ–†â–†â–„â–â–…â–‡â–‡â–‡â–‡â–…â–‡â–‡â–‚</td></tr><tr><td>step_profit</td><td>â–â–â–â–„â–â–â–â–ˆâ–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_res_count</td><td>â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_res_ratio</td><td>â–â–â–â–ˆâ–â–â–â–ˆâ–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_revenue</td><td>â–â–â–â–ƒâ–â–ƒâ–‚â–†â–‚â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–„â–„â–…â–„â–†â–‚â–„â–‚â–‡â–…â–†â–ˆâ–‡â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–…â–…</td></tr><tr><td>step_reward</td><td>â–‚â–…â–„â–‡â–â–…â–â–‡â–„â–…â–†â–â–„â–‚â–†â–ƒâ–…â–…â–‚â–„â–…â–…â–†â–…â–„â–‡â–ˆâ–…â–…â–…â–…â–…â–…â–„â–„â–…â–…â–‡â–â–†</td></tr><tr><td>step_won_count</td><td>â–‚â–„â–„â–…â–â–…â–‚â–…â–…â–…â–…â–‚â–„â–„â–‡â–„â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–‡â–…â–‡â–‡â–‡â–‡â–‡â–…â–…â–‡â–‡â–‡â–„â–ˆ</td></tr><tr><td>step_won_ratio</td><td>â–‚â–„â–„â–…â–â–…â–‚â–…â–…â–…â–…â–‚â–„â–„â–‡â–„â–‡â–‡â–…â–‡â–‡â–‡â–‡â–‡â–…â–ˆâ–‡â–…â–‡â–‡â–‡â–‡â–‡â–…â–…â–‡â–‡â–‡â–„â–ˆ</td></tr><tr><td>total_activ_count</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_lost_count</td><td>â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>total_not_part_count</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_res_count</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–</td></tr><tr><td>total_profit</td><td>â–â–â–â–‚â–‚â–‚â–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_profit_test</td><td>â–</td></tr><tr><td>total_res_count</td><td>â–â–â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_revenue</td><td>â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_reward</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_reward_test</td><td>â–</td></tr><tr><td>total_won_count</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2786</td></tr><tr><td>step_activ_count</td><td>0</td></tr><tr><td>step_activ_ratio</td><td>0</td></tr><tr><td>step_lost_count</td><td>0</td></tr><tr><td>step_not_activ_count</td><td>0</td></tr><tr><td>step_not_part_count</td><td>1</td></tr><tr><td>step_not_res_count</td><td>5</td></tr><tr><td>step_penalties</td><td>-1734.68615</td></tr><tr><td>step_profit</td><td>0.0</td></tr><tr><td>step_res_count</td><td>0</td></tr><tr><td>step_res_ratio</td><td>0.0</td></tr><tr><td>step_revenue</td><td>524.04</td></tr><tr><td>step_reward</td><td>0.30225</td></tr><tr><td>step_won_count</td><td>5</td></tr><tr><td>step_won_ratio</td><td>0.83333</td></tr><tr><td>total_activ_count</td><td>265</td></tr><tr><td>total_lost_count</td><td>2214</td></tr><tr><td>total_not_activ_count</td><td>0</td></tr><tr><td>total_not_part_count</td><td>5658</td></tr><tr><td>total_not_res_count</td><td>8585</td></tr><tr><td>total_penalties</td><td>-8967804.64226</td></tr><tr><td>total_profit</td><td>26889.25081</td></tr><tr><td>total_profit_test</td><td>512.12</td></tr><tr><td>total_res_count</td><td>265</td></tr><tr><td>total_revenue</td><td>1497971.84</td></tr><tr><td>total_reward</td><td>737.15116</td></tr><tr><td>total_reward_test</td><td>43.76</td></tr><tr><td>total_won_count</td><td>8850</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20221127_140558-1g9j2bam<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221127_140558-1g9j2bam/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-optuna/runs/1g9j2bam ... done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 14:11:38,930]\u001b[0m Trial 0 finished with value: 43.76 and parameters: {'learning_rate': 0.0005848158439951756, 'n_steps': 3, 'batch_size': 32, 'n_epochs': 10, 'gamma': 0.99, 'gae_lambda': 0.98, 'clip_range': 0.1, 'normalize_advantage': True, 'ent_coef': 0.0009728015659605418, 'vf_coef': 0.9541487034869848, 'max_grad_norm': 0.7, 'use_sde': False, 'target_kl': 0.03, 'lr_schedule': 'constant', 'net_arch': 'big', 'activation_fn': 'elu', 'ortho_init': True}. Best is trial 0 with value: 43.76.\u001b[0m\n",
      "\u001b[32m[I 2022-11-27 14:11:38,932]\u001b[0m A new study created in memory with name: no-name-de02e4ff-7447-4457-8ee0-7d2ff4f78e1a\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now tuning : TQC\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B syncing is set to <code>`offline`<code> in this directory.  <br/>Run <code>`wandb online`<code> or set <code>WANDB_MODE=online<code> to enable cloud syncing."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5951a4f4b3a84a7c8f9c9b6c2510bb19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 7.319258411300724e-05, 'batch_size': 16, 'buffer_size': 10000, 'learning_starts': 1, 'train_freq': 16, 'gradient_steps': 8, 'ent_coef': 'auto', 'tau': 0.005, 'gamma': 0.9999, 'policy_kwargs': {'net_arch': [64, 64], 'activation_fn': <class 'torch.nn.modules.activation.ReLU'>, 'n_quantiles': 48, 'use_sde': False}, 'target_entropy': 10, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.91961337 0.91961337 0.91961337 0.91961337 0.91961337 0.91961337\n",
      " 0.91961337 0.91961337 0.91961337 0.91961337 0.91961337 0.91961337]), 'top_quantiles_to_drop_per_net': 25}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reward on Test Set: 15.63\n",
      "Total Profit on Test Set: 0.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc264a5c6c5c4ff497f1ef8214514f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.000 MB of 0.000 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>step_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–</td></tr><tr><td>step_activ_ratio</td><td>â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–â–â–â–â–â–â–â–…â–</td></tr><tr><td>step_lost_count</td><td>â–†â–†â–†â–†â–†â–…â–…â–ˆâ–…â–ˆâ–â–…â–…â–…â–†â–ƒâ–†â–ƒâ–…â–ˆâ–…â–…â–…â–†â–ˆâ–†â–…â–ƒâ–ƒâ–…â–…â–ƒâ–ˆâ–ƒâ–†â–ƒâ–…â–ƒâ–…â–…</td></tr><tr><td>step_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>step_not_part_count</td><td>â–â–ƒâ–â–ƒâ–â–ƒâ–â–â–ƒâ–â–†â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–â–ƒâ–ƒâ–â–ƒâ–â–ƒâ–ƒâ–†â–†â–ƒâ–â–ƒâ–â–†â–â–â–ƒâ–ˆâ–â–ƒ</td></tr><tr><td>step_not_res_count</td><td>â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–†â–â–ƒâ–â–ƒâ–†â–ƒâ–ƒâ–â–†â–â–†â–â–â–ƒâ–ƒâ–†â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–â–ƒâ–ƒâ–ˆâ–ƒâ–â–ƒâ–ƒ</td></tr><tr><td>step_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–„â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–†â–ˆâ–ƒâ–ˆâ–†â–ˆâ–ˆâ–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–â–†â–ˆâ–‡â–‡â–‡â–‡â–ˆâ–‡â–‡</td></tr><tr><td>step_profit</td><td>â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–â–â–â–‡â–â–â–â–â–â–â–â–ˆâ–</td></tr><tr><td>step_res_count</td><td>â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–ˆâ–</td></tr><tr><td>step_res_ratio</td><td>â–â–â–â–â–â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–â–â–â–â–â–â–â–†â–</td></tr><tr><td>step_revenue</td><td>â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–ƒâ–‚â–ƒâ–â–„â–â–‚â–â–â–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–ƒâ–ˆâ–„â–â–‚â–â–ƒâ–‚â–â–‡â–‚</td></tr><tr><td>step_reward</td><td>â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–…â–‚â–„â–ƒâ–‡â–…â–ƒâ–„â–‚â–†â–â–„â–‚â–‚â–„â–„â–…â–‚â–‚â–‚â–„â–…â–…â–ƒâ–ˆâ–…â–‚â–„â–ƒâ–†â–ƒâ–â–ˆâ–…</td></tr><tr><td>step_won_count</td><td>â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–†â–â–ƒâ–â–†â–†â–ƒâ–ƒâ–â–†â–â–†â–â–â–ƒâ–ƒâ–†â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–â–ƒâ–ƒâ–ˆâ–ƒâ–â–†â–ƒ</td></tr><tr><td>step_won_ratio</td><td>â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–†â–â–ƒâ–â–†â–†â–ƒâ–ƒâ–â–†â–â–†â–â–â–ƒâ–ƒâ–†â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–†â–†â–â–ƒâ–ƒâ–ˆâ–ƒâ–â–†â–ƒ</td></tr><tr><td>total_activ_count</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_lost_count</td><td>â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_activ_count</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–</td></tr><tr><td>total_not_part_count</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_not_res_count</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_penalties</td><td>â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†â–…â–…â–…â–…â–…â–…â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–</td></tr><tr><td>total_profit</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_profit_test</td><td>â–</td></tr><tr><td>total_res_count</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>total_revenue</td><td>â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ</td></tr><tr><td>total_reward</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>total_reward_test</td><td>â–</td></tr><tr><td>total_won_count</td><td>â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>2799</td></tr><tr><td>step_activ_count</td><td>0</td></tr><tr><td>step_activ_ratio</td><td>0.0</td></tr><tr><td>step_lost_count</td><td>4</td></tr><tr><td>step_not_activ_count</td><td>0</td></tr><tr><td>step_not_part_count</td><td>2</td></tr><tr><td>step_not_res_count</td><td>0</td></tr><tr><td>step_penalties</td><td>0.0</td></tr><tr><td>step_profit</td><td>0.0</td></tr><tr><td>step_res_count</td><td>0</td></tr><tr><td>step_res_ratio</td><td>0.0</td></tr><tr><td>step_revenue</td><td>0.0</td></tr><tr><td>step_reward</td><td>0.12859</td></tr><tr><td>step_won_count</td><td>0</td></tr><tr><td>step_won_ratio</td><td>0.0</td></tr><tr><td>total_activ_count</td><td>345</td></tr><tr><td>total_lost_count</td><td>11766</td></tr><tr><td>total_not_activ_count</td><td>0</td></tr><tr><td>total_not_part_count</td><td>2645</td></tr><tr><td>total_not_res_count</td><td>2044</td></tr><tr><td>total_penalties</td><td>-1247269.66799</td></tr><tr><td>total_profit</td><td>43645.46618</td></tr><tr><td>total_profit_test</td><td>0.0</td></tr><tr><td>total_res_count</td><td>345</td></tr><tr><td>total_revenue</td><td>308908.2</td></tr><tr><td>total_reward</td><td>422.57045</td></tr><tr><td>total_reward_test</td><td>15.63</td></tr><tr><td>total_won_count</td><td>2389</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "You can sync this run to the cloud by running:<br/><code>wandb sync /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/offline-run-20221127_141138-g18646yh<code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/offline-run-20221127_141138-g18646yh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find logs at: /Users/Jan-Lukas.Pflaum/Dev/masterthesis/wandb/debug-cli.Jan-Lukas.Pflaum.log\n",
      "Syncing: https://wandb.ai/jlu237/RL-optuna/runs/g18646yh ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-11-27 14:16:53,631]\u001b[0m Trial 0 finished with value: 15.63 and parameters: {'learning_rate': 7.319258411300724e-05, 'batch_size': 16, 'buffer_size': 10000, 'tau': 0.005, 'gamma': 0.9999, 'train_freq': 16, 'gradient_steps': 8, 'learning_starts': 1, 'noise_type': 'normal', 'noise_std': 0.9196133716435153, 'policy_delay': 5, 'target_policy_noise': 0.1, 'ent_coef': 'auto', 'target_entropy': 10, 'net_arch': 'small', 'use_sde': False, 'activation_fn': 'relu', 'n_quantiles': 48, 'top_quantiles_to_drop_per_net': 25}. Best is trial 0 with value: 15.63.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n"
     ]
    }
   ],
   "source": [
    "algo_list = [\"SAC\", \"DDPG\", \"TD3\", \"TRPO\", \"R_PPO\", \"A2C\", \"PPO\", \"TQC\"]\n",
    "\n",
    "for algo in algo_list:\n",
    "    study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "    study.set_user_attr(\"algo\", algo)\n",
    "    print(\"Now tuning : \" + algo)\n",
    "\n",
    "    try:\n",
    "        study.optimize(optimize_agent, n_trials=N_TRIALS, timeout=10800)        \n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print('Interrupted by keyboard.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7743327e-d3ad-435f-898c-9fe65edfc5df",
   "metadata": {},
   "source": [
    "## Single Algorithm "
   ]
  },
  {
   "cell_type": "raw",
   "id": "6f4983a7-f32e-4465-82a1-667092409d46",
   "metadata": {
    "tags": []
   },
   "source": [
    "ALGORITHM = \"R_PPO\"\n",
    "\n",
    "study = optuna.create_study(sampler=sampler, pruner=pruner, direction=\"maximize\")\n",
    "study.set_user_attr(\"algo\", ALGORITHM)\n",
    "\n",
    "try:\n",
    "    study.optimize(optimize_agent, n_trials=N_TRIALS, timeout=10800)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print('Interrupted by keyboard.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
